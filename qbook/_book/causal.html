<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Advanced Data Science for Public Health - 18&nbsp; Causal DAGs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./validation.html" rel="next">
<link href="./graphics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Causal DAGs</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Data Science for Public Health</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/smart-stats/advanced_ds4bio_book" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interactive.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interactive graphics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./webscraping.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Advanced web scrapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./databases.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Databases</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pipelines.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pipelines</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_structures.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data structures</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diymlai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">DIY ML/AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./images.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Working with images</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convnet_example.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Convolutional AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./variationalAEs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Variational autoencoders</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nlp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">NLP</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Measurement</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_analysis_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Data science, conceptually</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat_language.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Statistics and language</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_science_as_a_science.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Data science as an applied science</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./graphics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Theory of graphical display</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Causal DAGs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Machine learning validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ethics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Ethics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#associational-models-versus-causal-models" id="toc-associational-models-versus-causal-models" class="nav-link active" data-scroll-target="#associational-models-versus-causal-models"><span class="toc-section-number">18.1</span>  Associational models versus causal models</a>
  <ul class="collapse">
  <li><a href="#graphs-and-graphical-models" id="toc-graphs-and-graphical-models" class="nav-link" data-scroll-target="#graphs-and-graphical-models"><span class="toc-section-number">18.1.1</span>  Graphs and graphical models</a></li>
  <li><a href="#dag-and-scms" id="toc-dag-and-scms" class="nav-link" data-scroll-target="#dag-and-scms"><span class="toc-section-number">18.1.2</span>  DAG and SCMs</a></li>
  <li><a href="#blocking-and-d-separation" id="toc-blocking-and-d-separation" class="nav-link" data-scroll-target="#blocking-and-d-separation"><span class="toc-section-number">18.1.3</span>  Blocking and d-separation</a></li>
  </ul></li>
  <li><a href="#do-calculus-and-backdoor-criterion" id="toc-do-calculus-and-backdoor-criterion" class="nav-link" data-scroll-target="#do-calculus-and-backdoor-criterion"><span class="toc-section-number">18.2</span>  Do calculus and backdoor criterion</a>
  <ul class="collapse">
  <li><a href="#example-graphs" id="toc-example-graphs" class="nav-link" data-scroll-target="#example-graphs"><span class="toc-section-number">18.2.1</span>  Example graphs</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">18.3</span>  Exercises</a>
  <ul class="collapse">
  <li><a href="#graphs" id="toc-graphs" class="nav-link" data-scroll-target="#graphs"><span class="toc-section-number">18.3.1</span>  Graphs</a></li>
  <li><a href="#data-exercise" id="toc-data-exercise" class="nav-link" data-scroll-target="#data-exercise"><span class="toc-section-number">18.3.2</span>  Data exercise</a></li>
  </ul></li>
  <li><a href="#reading" id="toc-reading" class="nav-link" data-scroll-target="#reading"><span class="toc-section-number">18.4</span>  Reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Causal DAGs</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="associational-models-versus-causal-models" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="associational-models-versus-causal-models"><span class="header-section-number">18.1</span> Associational models versus causal models</h2>
<p>Causal models differ from associational models in that they codify causal directions not just associations. In our program, you might have learned of the use of propensity scores, counterfactuals or randomization to study causality. There, typically the goal is to make causal statements with as few assumptions as possible or at least understanding the assumptions. Typically, the object of study is the estimation of an effect avergated over covarites.</p>
<p>Causal graphs take a different approach, even if they wind up at the same place. Here, the goal is to postulate hyptothetical causal relationships and use those hypothetical relationships to estimate causal effects.</p>
<section id="graphs-and-graphical-models" class="level3" data-number="18.1.1">
<h3 data-number="18.1.1" class="anchored" data-anchor-id="graphs-and-graphical-models"><span class="header-section-number">18.1.1</span> Graphs and graphical models</h3>
<p>A graph, <span class="math inline">\(G\)</span> is a collection of nodes, say <span class="math inline">\(V=\{1,\ldots, p\}\)</span> and a set edges between the nodes, i.e.&nbsp;a set of elements <span class="math inline">\((i,j)\)</span>. The graph is directed if <span class="math inline">\((i,j)\)</span> is considered different then <span class="math inline">\((j,i)\)</span>.</p>
<p>Node <span class="math inline">\(i\)</span> is a parent of node <span class="math inline">\(j\)</span> if <span class="math inline">\((i,j) \in E\)</span> and <span class="math inline">\((j,i)\notin E\)</span>. Similarly, node <span class="math inline">\(i\)</span> is a <strong>child</strong> of node <span class="math inline">\(j\)</span> if <span class="math inline">\((j,i) \in E\)</span> and <span class="math inline">\((i,j)\notin E\)</span>. A node is a <strong>descendant</strong> of another if it is a child, or a child of a child and so on.</p>
</section>
<section id="dag-and-scms" class="level3" data-number="18.1.2">
<h3 data-number="18.1.2" class="anchored" data-anchor-id="dag-and-scms"><span class="header-section-number">18.1.2</span> DAG and SCMs</h3>
<p>DAGs define a unique factorization (set of independence relationships) with compatible probability models. I find it useful to think of causal DAGs in the terms of structural causal models (SCMs). Such models demonstrate an example of a generative models that statisfy the DAG and the have clear connections with the probabability models. An SCM over a collection of variables, <span class="math inline">\(X=(X_1, \ldots, X_p)\)</span>, postulates a set of functional relationships <span class="math display">\[
X_j = f(P_j, \epsilon_j)
\]</span> where <span class="math inline">\(P_j\)</span> are the antecedent causes of <span class="math inline">\(X_j\)</span>, called the parents of <span class="math inline">\(X_j\)</span>, and <span class="math inline">\(\epsilon_j\)</span> is an accumulation of variables treated as mutally independent. This defines a directed graph, <span class="math inline">\(G\)</span> say, where a graph is collection of vertices corresponding to our variables, <span class="math inline">\(V=\{1,\ldots, p\}\)</span>, corresponding to the <span class="math inline">\(X_i\)</span>, and edges, <span class="math inline">\(E\)</span>, which is a set of ordered pairs of nodes.</p>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-3-output-1.png" width="307" height="307"></p>
</div>
</div>
<p>In this case, <span class="math inline">\(P_1 = \{\}\)</span>, <span class="math inline">\(P_2 = \{1\}\)</span> and <span class="math inline">\(P_3 = \{1,2\}\)</span>. DAGs in general define the independence assumptions associated with compatible probability models. SCMs are such an example that clearly define compatible probability models. Of course, given a large enough cross-sectional sample, we can estimate the joint distribution of <span class="math inline">\(P(X_1,\ldots, X_p)\)</span> and all of its conditionals. Disregarding statistical variation, which can be accounted for using traditional inferential methods, these conditionals should agree with the independence relationships from the DAG, if the DAG is correct. This yields a fruitful way to consider probability models. For example one could use DAGs as a heuristic and see how the observed data agrees with the independence relationships in compatible probability models implied by the DAG.</p>
<p>By itself, this does not create any causal claims. However, the following strategy could. Postulate a causal model, like the SCM, consider the independence relationships implied by the SCM, compares those indepnence relationships with those seen in the observed data. This gives us a method to falsify causal models using the data.</p>
<p>One specific way in which we use the assumptions is to investigate how the graph changes when we fix a node at a specific value, like an intevention, thus breaking its association with its parents. This operation is conceptual, but at times we can relate probabilities associated with interventions that were not realized. Consider an instrance where where <span class="math inline">\(X_1\)</span> is a collection of confounders, <span class="math inline">\(X_2\)</span> is an exposure and <span class="math inline">\(X_3\)</span> is an outcome. Ideally, we’d like to know <span class="math display">\[
P(X_3 ~|~ do(X_2) = x_2)
\]</span> That is, the impact on the response if we were to set the exposure to <span class="math inline">\(e_0\)</span>.</p>
</section>
<section id="blocking-and-d-separation" class="level3" data-number="18.1.3">
<h3 data-number="18.1.3" class="anchored" data-anchor-id="blocking-and-d-separation"><span class="header-section-number">18.1.3</span> Blocking and d-separation</h3>
<p>Before we talk about interventions, let’s consider discussing compatibility of the hypothetical directed graph and our observed data. Return to our previous diagram.</p>
<ul>
<li><span class="math inline">\(X1\)</span> is a <em>confounder</em> betweend <span class="math inline">\(X2\)</span> and <span class="math inline">\(X3\)</span></li>
<li><span class="math inline">\(X2\)</span> is a <em>mediator</em> between <span class="math inline">\(X1\)</span> and <span class="math inline">\(X3\)</span></li>
<li><span class="math inline">\(X3\)</span> is a <em>collider</em> between <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span></li>
</ul>
<p>Consider an example. <span class="math inline">\(X1\)</span> is having a BMI &gt; 35, <span class="math inline">\(X2\)</span> is sleep disordered breathing and <span class="math inline">\(X3\)</span> is hypertension.</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-4-output-1.png" width="307" height="307"></p>
</div>
</div>
<p>Here if we’re studying whether SDB causes HTN, BMI35 confounds the relationship as a possible common cause of both. We would need to adjust for BMI35 to make sure the association between SDB and HTN isn’t just due to this common cause.</p>
<p>If we were studying whether BMI35 causes HTN, we might be interested in how much of that effect is mediated (indirectly) through SDB and how much is directly from BMI35.</p>
<p>If we are studying the relationship between BMI35 and SDB directly, adjusting for HTN may cause an association. Consider the (fictitious) case where there is a large number of people who have SDB who are not obese, yet all have hypertension, for whatever the reason. Then, among the HTN, there could be a negative association between BMI35 and SDB, because of the large collection of patients would who have SDB and are not obese and the same for obese and not hyptertensive. That is, adjusting for HTN created an association. This is an example of <a href="https://en.wikipedia.org/wiki/Berkson%27s_paradox">Berkson’s paradox</a>. This is a somewhat contrived example, but hopefully you get the point. The wikipedia article has a funny example where they consider <span class="math inline">\(X_1\)</span> is whether or not the hamburger is good at a fast food restaurant, <span class="math inline">\(X_2\)</span> is whether or not the fries are good and <span class="math inline">\(X_3\)</span> is whether or not people eat there. Since few people would eat at a place where both the hamburger and fries are bad, conditioning on <span class="math inline">\(X_3\)</span> can create a negative association.</p>
<p>The main point here is that adjusting for colliders may open up a pathway between the nodes.</p>
<p>A <strong>path</strong> between two nodes <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_k\)</span> is a sequence of nodes, <span class="math inline">\(v_1, v_2,\ldots v_{k}\)</span>, where <span class="math inline">\(v_{i}\)</span> and <span class="math inline">\(v_{i+1}\)</span> are connected. The path is <strong>directed</strong> if <span class="math inline">\(v_{i}\)</span> points to <span class="math inline">\(v_{i+1}\)</span> for <span class="math inline">\(i=1,\ldots,k\)</span>. A graph is a Directed Acyclic Graph (DAG) if all edges are directed and there are no two nodes <span class="math inline">\(v_i\)</span> and <span class="math inline">\(v_j\)</span> with a directed path in both directions.</p>
<p>A path between <span class="math inline">\(v_1\)</span> and <span class="math inline">\(v_k\)</span>, <span class="math inline">\(v_1,\ldots, v_k\)</span>, is blocked by a set of nodes, <span class="math inline">\(S\)</span>, if for some <span class="math inline">\(v_j\)</span> in <span class="math inline">\(S\)</span></p>
<ol type="1">
<li><span class="math inline">\(v_j\in S\)</span> and <span class="math inline">\(v_k\)</span> is a mediator or confounder between <span class="math inline">\(v_{j-1}\)</span> and <span class="math inline">\(v_{j+1}\)</span> in either direction <strong>or</strong></li>
<li><span class="math inline">\(v_j\notin S\)</span> and all of the descendants of <span class="math inline">\(v_j \notin S\)</span> and <span class="math inline">\(v_{j}\)</span> is a collider between <span class="math inline">\(v_{j-1}\)</span> and <span class="math inline">\(v_{j+1}\)</span>.</li>
</ol>
<p>In other words, a path is <strong>blocked</strong> if a mediator or confounder is included in <span class="math inline">\(S\)</span> or a collider and all of its descendants is excluded from <span class="math inline">\(S\)</span>.</p>
<p>For 1. this is equivalent to saying one of</p>
<ul>
<li><span class="math inline">\(v_{j-1}\rightarrow v_{j} \rightarrow v_{j+1}\)</span></li>
<li><span class="math inline">\(v_{j-1}\leftarrow v_{j} \leftarrow v_{j+1}\)</span></li>
<li><span class="math inline">\(v_{j-1}\leftarrow v_{j} \rightarrow v_{j+1}\)</span></li>
</ul>
<p>holds. For 2. recall a collider is <span class="math inline">\(v_{j-1}\rightarrow v_{j} \leftarrow v_{j+1}\)</span>.</p>
<p>This could be translated into the following statistical statement. Conditioning on a mediator or confounder or <strong>not</strong> conditioning on a collider blocks a path, conditioning on a collider opens a path.</p>
<p>We say that two nodes or groups of nodes are <strong>d-separated</strong> by a set of nodes, <span class="math inline">\(S\)</span>, if every path between nodes in the two groups is blocked by <span class="math inline">\(S\)</span>. d-separation is useful because it gives us conditional independence relationships in the sense that if <span class="math inline">\(X_i\)</span> is d-separated with <span class="math inline">\(X_j\)</span> given <span class="math inline">\(S\)</span> then <span class="math inline">\(X_i \perp X_j ~|~ S\)</span> on all probability distribution compatible with the graph.</p>
<p>Consider the following graph.</p>
<div class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-5-output-1.png" width="307" height="307"></p>
</div>
</div>
<p><span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_5\)</span> are conditionally indepndent given <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_3\)</span>. Why? Conditioning on <span class="math inline">\(X_2\)</span> blocks the paths <span class="math inline">\(X_1 \leftarrow X_2 \rightarrow X_3 \leftarrow X_5\)</span> even despite the part <span class="math inline">\(X_2 \rightarrow X_3 \leftarrow X_5\)</span> is opened by conditioning on the collider, <span class="math inline">\(X_3\)</span>. Furthermore, conditioning on <span class="math inline">\(X_2\)</span> or <span class="math inline">\(X_3\)</span> blocks the path <span class="math inline">\(X_1 \leftarrow X_2 \rightarrow X_3 \rightarrow X_4 \rightarrow X_6 \leftarrow X_5\)</span>. Finally, conditioning on <span class="math inline">\(X_3\)</span> blocks the path <span class="math inline">\(X_1 \leftarrow X_3 \leftarrow X_5\)</span>.</p>
<p>Another interesting one is that <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_5\)</span> are marginally independent. This is because <strong>not</strong> conditioining on <span class="math inline">\(X_3\)</span> blocks the path <span class="math inline">\(X_2 \rightarrow X_3 \leftarrow X_5\)</span> and <strong>not</strong> conditioning on <span class="math inline">\(X_6\)</span> blocks the path <span class="math inline">\(X_2 \rightarrow X_3 \rightarrow X_4 \rightarrow X_6 \leftarrow X_5\)</span>.</p>
<p>Here’s the complete set of conditional independence relationships.</p>
<ol type="1">
<li><span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_4\)</span> are d-separated by <span class="math inline">\(\{X_3\}\)</span></li>
<li><span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_5\)</span> are d-separated by <span class="math inline">\(\{X_2, X_3\}\)</span></li>
<li><span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_6\)</span> are d-separated by <span class="math inline">\(\{X_4, X_5\}\)</span>, <span class="math inline">\(\{X_3, X_5\}\)</span>, <span class="math inline">\(\{X_2, X_3\}\)</span></li>
<li><span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_4\)</span> are d-separated by <span class="math inline">\(\{X_3\}\)</span></li>
<li><span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_5\)</span> are d-separated by <span class="math inline">\(\{\}\)</span> (the null set, i.e.&nbsp;they’re marginally independent).</li>
<li><span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_6\)</span> are d-separated by <span class="math inline">\(\{X_4, X_5\}\)</span>, <span class="math inline">\(\{X_3, X_5\}\)</span></li>
<li><span class="math inline">\(X_3\)</span> and <span class="math inline">\(X_6\)</span> are d-separated by <span class="math inline">\(\{X_4, X_5\}\)</span></li>
<li><span class="math inline">\(X_4\)</span> and <span class="math inline">\(X_5\)</span> are d-separated by <span class="math inline">\(X_3\)</span>.</li>
</ol>
<p>These all imply the independence relationships, such as <span class="math inline">\(X_1 \perp X_4 ~|~ X_3\)</span>.</p>
</section>
</section>
<section id="do-calculus-and-backdoor-criterion" class="level2" data-number="18.2">
<h2 data-number="18.2" class="anchored" data-anchor-id="do-calculus-and-backdoor-criterion"><span class="header-section-number">18.2</span> Do calculus and backdoor criterion</h2>
<p>Recall that specifying a causal graph implies the independence relationships of a probability distribution under assumptions such as the SCM. Sometimes, we’re interested in the causal relationship between an exposure, <span class="math inline">\(X\)</span> and an outcome, <span class="math inline">\(Y\)</span>. Consider a theoretical intervention obtained by setting <span class="math inline">\(X = a\)</span>, which we write as <span class="math inline">\(do(X) = a\)</span>. We want to estimate <span class="math inline">\(P(Y ~|~ do(X) = a)\)</span>.</p>
<p>A set <span class="math inline">\(Z\)</span> satisfies the <strong>back door</strong> criterion with respect to nodes <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> if</p>
<ol type="1">
<li>No descendant of <span class="math inline">\(X\)</span> is in <span class="math inline">\(Z\)</span>.</li>
<li><span class="math inline">\(Z\)</span> blocks every path <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> that contains an arrow pointing to <span class="math inline">\(X\)</span>.</li>
</ol>
<p>The back door criteria is similar to d-separation. However, we only focus on arrows pointing into <span class="math inline">\(X\)</span> and don’t allow for descendants of <span class="math inline">\(X\)</span>.</p>
<p>The magic of the back door adjustment comes from the relationship, the adjustment formula:</p>
<p><span class="math display">\[
P(Y ~|~ do(X) = x) = \sum_{z\in S} P(y ~ | x, z) p(z)
\]</span></p>
<p>where <span class="math inline">\(S\)</span> satisfies the back door criterion. If the <span class="math inline">\(z\)</span> are all observed variables, then the RHS of this equation is estimable. Note the interesting statement that not all variables need to be observed, just <span class="math inline">\(y\)</span>, <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span>.</p>
<p>So, in our previous example, adjusting for <span class="math inline">\(S = \{X_2, X_3\}\)</span> allows us to estimate the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, even if <span class="math inline">\(X_4\)</span> and <span class="math inline">\(X_5\)</span> are not measured.</p>
<p>It’s important to emphasize, that every aspect of the adjustment formula is theoretically estimable if <span class="math inline">\(Y\)</span>, <span class="math inline">\(X\)</span> and the nodes in <span class="math inline">\(S\)</span> are observed.</p>
<p>Consider the following graph.</p>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-6-output-1.png" width="307" height="307"></p>
</div>
</div>
<p>Here are the minimal backdoor adjustment variables between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(S = \{X_2, X_3\}\)</span></li>
<li><span class="math inline">\(S = \{X_3, X_5\}\)</span></li>
<li><span class="math inline">\(S = \{X_4, X_5\}\)</span></li>
</ol>
<p>Here are some <strong>invalid</strong> backdoor sets of variables.</p>
<ol type="1">
<li><span class="math inline">\(S\)</span> equal to any single node.
<ol type="1">
<li><span class="math inline">\(S=\{X_3\}\)</span> does not block the path <span class="math inline">\(X\leftarrow X_2 \rightarrow X_3 \leftarrow X_5 \rightarrow Y\)</span>.</li>
<li><span class="math inline">\(S=\{X_4\}\)</span> or <span class="math inline">\(S=\{X_2\}\)</span> does not block the path <span class="math inline">\(X \leftarrow X_3 \leftarrow X_5 \rightarrow Y\)</span>.</li>
<li><span class="math inline">\(S=\{X_5\}\)</span> does not block the path <span class="math inline">\(X \leftarrow X_3 \leftarrow X_4 \rightarrow Y\)</span>.</li>
</ol></li>
<li><span class="math inline">\(S=\{X_3, X_4\}\)</span> does not block the path <span class="math inline">\(X \leftarrow X_2 \rightarrow X_3 \leftarrow X_5 \rightarrow Y\)</span>.</li>
<li><span class="math inline">\(S=\{X_2, X_4\}\)</span> does not block the path <span class="math inline">\(X\leftarrow X_3 \leftarrow X_5 \rightarrow Y\)</span>.</li>
</ol>
<section id="example-graphs" class="level3" data-number="18.2.1">
<h3 data-number="18.2.1" class="anchored" data-anchor-id="example-graphs"><span class="header-section-number">18.2.1</span> Example graphs</h3>
<p>In all the following, we’re interested in the causal effect of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. <span class="math inline">\(Z\)</span> variables are observed and <span class="math inline">\(U\)</span> variables are unobserved. Every variable is binary to make the discussion easier.</p>
<section id="randomization" class="level4" data-number="18.2.1.1">
<h4 data-number="18.2.1.1" class="anchored" data-anchor-id="randomization"><span class="header-section-number">18.2.1.1</span> Randomization</h4>
<p>If <span class="math inline">\(X\)</span> is randomized <strong>and everyone takes the treatment assigned to them</strong> (left plot) then <span class="math inline">\(X\)</span> has no parents other than the randomization mechanism,<span class="math inline">\(R\)</span>. We’re omitting any descendants of <span class="math inline">\(X\)</span> since we don’t have to worray about them. Regardless of the complexity of the relationship between the collection of observed, unobserved, known and unknown variables, <span class="math inline">\(Z, U\)</span>, and <span class="math inline">\(Y\)</span> we can estimate the causal effect simply without conditioning on anything.</p>
<p>In contrast, if some people ignore their randomized treatment status and elect to choose a different treatment one may have opened a backdoor path (right plot). For example, if the treatment can’t be blinded and those randomized to the control with the worst baseline symptoms elect to obtain the treatment elsewhere.</p>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-7-output-1.png" width="466" height="241"></p>
</div>
</div>
</section>
<section id="simple-confounding" class="level4" data-number="18.2.1.2">
<h4 data-number="18.2.1.2" class="anchored" data-anchor-id="simple-confounding"><span class="header-section-number">18.2.1.2</span> Simple confounding</h4>
<p>The diagram below shows classic confounding. Conditioning in <span class="math inline">\(Z\)</span> allows for the estimation of the causal effect.</p>
<div class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-8-output-1.png" width="307" height="307"></p>
</div>
</div>
<p>Now the estimate of the adjusted effect (under our assumptions) is</p>
<p><span class="math display">\[
P(Y ~|~ do(X) = x) = P(Y ~|~ X=x, z = 0)P(z = 0) + P(Y ~|~ X=x, Z=1)P(Z=1)
\]</span></p>
<p>In the following two examples, the unmeasured confounder <span class="math inline">\(U\)</span> can be controlled for by conditioning on <span class="math inline">\(Z\)</span> and exactly the same estimate can be used as in the simple confounding model.</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(-0.3, 1.3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-9-output-2.png" width="466" height="241"></p>
</div>
</div>
</section>
<section id="mediation" class="level4" data-number="18.2.1.3">
<h4 data-number="18.2.1.3" class="anchored" data-anchor-id="mediation"><span class="header-section-number">18.2.1.3</span> Mediation</h4>
<p>In mediation, all or part of the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> flows through yet another variable <span class="math inline">\(Z\)</span>.</p>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-10-output-1.png" width="307" height="307"></p>
</div>
</div>
<p>The backdoor criteria does not apply here, since <span class="math inline">\(Z\)</span> is a descendant of <span class="math inline">\(X\)</span>. To answer the question “What is the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>?” one need not adjust. However, mediation is typically studied in a different way. Instead, one asks questions such as “How much of the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> flows or doesn’t flow through <span class="math inline">\(Z\)</span>?”. To answer this question, one usually conditions on <span class="math inline">\(Z\)</span> for a different goal than the backdoor adjustment is accomplishing.</p>
<p><span class="citation" data-cites="cinelli2021crash">Cinelli, Forney, and Pearl (<a href="references.html#ref-cinelli2021crash" role="doc-biblioref">2021</a>)</span> shows an interesting example of mediation where one would want to adjust for <span class="math inline">\(Z\)</span> (left plot below).</p>
<div class="cell" data-execution_count="11">
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(-0.3, 1.3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-11-output-2.png" width="763" height="241"></p>
</div>
</div>
<p>In this case, <span class="math inline">\(M\)</span> still mediates the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. However, <span class="math inline">\(Z\)</span> is in a backdoor path to <span class="math inline">\(M\)</span>. So, some of the variation in <span class="math inline">\(M\)</span> that impacts <span class="math inline">\(Y\)</span> could be due to <span class="math inline">\(Z\)</span> rather than <span class="math inline">\(X\)</span>. The right plot is similar and makes the point more explicit. <span class="math inline">\(Z\)</span> confounds the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> through <span class="math inline">\(M\)</span>. Without adjusting for <span class="math inline">\(Z\)</span>, the path <span class="math inline">\(X\leftarrow Z \rightarrow M \rightarrow Y\)</span> remains unblocked.</p>
</section>
<section id="bad-controls" class="level4" data-number="18.2.1.4">
<h4 data-number="18.2.1.4" class="anchored" data-anchor-id="bad-controls"><span class="header-section-number">18.2.1.4</span> Bad controls</h4>
<p>The following are all unhelpful for conditioning on <span class="math inline">\(Z\)</span> using the backdoor criteria.</p>
<p>Upper left. Adjusting for colliders is the standard bad control. Below adjusting for <span class="math inline">\(Z\)</span> open ups a backdoor path that was closed. From a common sense perspective, why would you want to adjust for a consequence of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> when exploring their relationship?</p>
<p>In the upper right diagram below, <span class="math inline">\(Z\)</span> is a so-called <strong>instrumental</strong> variable. A good example is <span class="math inline">\(Z\)</span> being the randomization indicator and <span class="math inline">\(X\)</span> being the treatment the person actually took. It is important in this example to emphasize that use of the instrumental variable is often a very fruitful method of analysis. However, it’s not a useful backdoor adjustment and conditioning on <span class="math inline">\(Z\)</span> simply removes most of the relevant variation in <span class="math inline">\(X\)</span>. If one wants to use <span class="math inline">\(Z\)</span> as an instrumental variable in this setting, then specific methods taylored to instrumental variable use need to be employed.</p>
<p>In the lower left plot, <span class="math inline">\(Z\)</span> is a descendant of <span class="math inline">\(X\)</span>. Conditioning on <span class="math inline">\(Z\)</span> removes relevant pathway information regarding the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>&gt;</p>
<p>The lower right plot is similar. Conditioning on <span class="math inline">\(Z\)</span> removes variation in <span class="math inline">\(M\)</span> which hinders our ability to study the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> through <span class="math inline">\(M\)</span>.</p>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-12-output-1.png" width="466" height="463"></p>
</div>
</div>
</section>
<section id="conditioning-may-help" class="level4" data-number="18.2.1.5">
<h4 data-number="18.2.1.5" class="anchored" data-anchor-id="conditioning-may-help"><span class="header-section-number">18.2.1.5</span> Conditioning may help</h4>
<p>In the upper left plot, adjusting for <span class="math inline">\(Z\)</span> may reduce variability in <span class="math inline">\(Y\)</span> to help focus on the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>In the upper left plot, adjusting for <span class="math inline">\(Z\)</span> may reduce variation in the mediator unrelated to the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>(-0.3, 1.3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-13-output-2.png" width="466" height="241"></p>
</div>
</div>
</section>
</section>
</section>
<section id="exercises" class="level2" data-number="18.3">
<h2 data-number="18.3" class="anchored" data-anchor-id="exercises"><span class="header-section-number">18.3</span> Exercises</h2>
<section id="graphs" class="level3" data-number="18.3.1">
<h3 data-number="18.3.1" class="anchored" data-anchor-id="graphs"><span class="header-section-number">18.3.1</span> Graphs</h3>
<p>Consider the following graph where we want to answer the question: what is <span class="math inline">\(P(Y ~|~ do(X) = x)\)</span> where every variable is binary.</p>
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(-0.3, 1.3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-14-output-2.png" width="307" height="307"></p>
</div>
</div>
<ol type="1">
<li>What are the minimal set of adjustment variables for the backdoor criteria?</li>
<li>Is <span class="math inline">\(X \perp Y ~|~ Z_1, Z_2\)</span>?</li>
<li>Is <span class="math inline">\(X \perp Y ~|~ Z_2, Z_3\)</span>?</li>
<li>Given a cross sectional sample, if <span class="math inline">\(Z_3\)</span> is unobserved, give a formula for the estimation of <span class="math inline">\(P(Y ~|~ do(X) = x)\)</span> that only requires observed variables.</li>
</ol>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-15-output-1.png" width="307" height="307"></p>
</div>
</div>
<ol type="1">
<li>What are the minimal set of adjustment variables for the backdoor criteria?</li>
<li>Given a cross sectional sample, give a formula for the estimation of <span class="math inline">\(P(Y ~|~ do(X) = x)\)</span> that only requires observed variables.</li>
</ol>
</section>
<section id="data-exercise" class="level3" data-number="18.3.2">
<h3 data-number="18.3.2" class="anchored" data-anchor-id="data-exercise"><span class="header-section-number">18.3.2</span> Data exercise</h3>
<p>The wikipedia page on Simpson’s paradox gives this data concerning two treatments of kidney stones, the percentage of succcessful procedures and the size of the stone. Note, among both large stones and small stones A is better than B. However, among all B is preferable to A.</p>
<table class="table">
<thead>
<tr class="header">
<th>Size</th>
<th>Treatment</th>
<th>Success</th>
<th>N</th>
<th>Prop</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Large</td>
<td>A</td>
<td>192</td>
<td>263</td>
<td>73%</td>
</tr>
<tr class="even">
<td></td>
<td>B</td>
<td>55</td>
<td>80</td>
<td>69%</td>
</tr>
<tr class="odd">
<td>Small</td>
<td>A</td>
<td>81</td>
<td>87</td>
<td>93%</td>
</tr>
<tr class="even">
<td></td>
<td>B</td>
<td>234</td>
<td>270</td>
<td>87%</td>
</tr>
<tr class="odd">
<td>Both</td>
<td>A</td>
<td>273</td>
<td>350</td>
<td>78%</td>
</tr>
<tr class="even">
<td></td>
<td>B</td>
<td>289</td>
<td>350</td>
<td>83%</td>
</tr>
</tbody>
</table>
<p>Estimate the treatment effect difference: <span class="math display">\[
P(Success ~|~ Do(Treatment) = B)
- P(Success ~|~ Do(Treatment) = A)
\]</span> under the following graphical models where <span class="math inline">\(X\)</span> is treatment, <span class="math inline">\(Y\)</span> is success and <span class="math inline">\(Z\)</span> is stone size:</p>
<div class="cell" data-execution_count="16">
<div class="cell-output cell-output-display">
<p><img src="causal_files/figure-html/cell-16-output-1.png" width="466" height="463"></p>
</div>
</div>
<p>Comment on how reasonable each of these models are given the setting. Here’s a reference: <span class="citation" data-cites="julious1994confounding">Julious and Mullee (<a href="references.html#ref-julious1994confounding" role="doc-biblioref">1994</a>)</span>.</p>
<p>Give any other DAGs, perhaps including unmeasured variables, that you think are relevant.</p>
</section>
</section>
<section id="reading" class="level2" data-number="18.4">
<h2 data-number="18.4" class="anchored" data-anchor-id="reading"><span class="header-section-number">18.4</span> Reading</h2>
<ul>
<li>The definitive causal reference is <span class="citation" data-cites="pearl2009causality">Pearl (<a href="references.html#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span>.</li>
<li>I got a lot of this stuff from <span class="citation" data-cites="peters2017elements">Peters, Janzing, and Schölkopf (<a href="references.html#ref-peters2017elements" role="doc-biblioref">2017</a>)</span>, which you can read <a href="https://library.oapen.org/bitstream/id/056a11be-ce3a-44b9-8987-a6c68fce8d9b/11283.pdf">here</a></li>
<li>Also read <span class="citation" data-cites="hardt2021patterns">Hardt and Recht (<a href="references.html#ref-hardt2021patterns" role="doc-biblioref">2021</a>)</span>, which you can read <a href="https://mlstory.org/index.html">here</a></li>
<li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf">A crash course in good and bad controls</a>, or <a href="http://causality.cs.ucla.edu/blog/index.php/category/back-door-criterion/">here</a></li>
<li><a href="http://dagitty.net/.html#">dagitty</a></li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-cinelli2021crash" class="csl-entry" role="doc-biblioentry">
Cinelli, Carlos, Andrew Forney, and Judea Pearl. 2021. <span>“A Crash Course in Good and Bad Controls.”</span> <em>Sociological Methods &amp; Research</em>, 00491241221099552.
</div>
<div id="ref-hardt2021patterns" class="csl-entry" role="doc-biblioentry">
Hardt, Moritz, and Benjamin Recht. 2021. <span>“Patterns, Predictions, and Actions: A Story about Machine Learning.”</span> <em>arXiv Preprint arXiv:2102.05242</em>.
</div>
<div id="ref-julious1994confounding" class="csl-entry" role="doc-biblioentry">
Julious, Steven A, and Mark A Mullee. 1994. <span>“Confounding and Simpson’s Paradox.”</span> <em>Bmj</em> 309 (6967): 1480–81.
</div>
<div id="ref-pearl2009causality" class="csl-entry" role="doc-biblioentry">
Pearl, Judea. 2009. <em>Causality</em>. Cambridge university press.
</div>
<div id="ref-peters2017elements" class="csl-entry" role="doc-biblioentry">
Peters, Jonas, Dominik Janzing, and Bernhard Schölkopf. 2017. <em>Elements of Causal Inference: Foundations and Learning Algorithms</em>. The MIT Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./graphics.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Theory of graphical display</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./validation.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Machine learning validation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>