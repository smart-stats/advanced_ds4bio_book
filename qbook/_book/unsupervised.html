<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Advanced Data Science for Public Health - 11&nbsp; Unsupervised learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./data_analysis_theory.html" rel="next">
<link href="./convnet_example.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Data Science for Public Health</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/smart-stats/advanced_ds4bio_book" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interactive.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interactive graphics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./webscraping.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Advanced web scrapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nlp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">NLP</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./images.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Working with images</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./databases.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Databases</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pipelines.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pipelines</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_structures.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Data structures</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diymlai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">DIY ML/AI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convnet_example.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Example convnet</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_analysis_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Data science, conceptually</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_science_as_a_science.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Data science as an applied science</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./graphics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Theory of graphical display</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#pca" id="toc-pca" class="nav-link active" data-scroll-target="#pca"><span class="toc-section-number">11.1</span>  PCA</a>
  <ul class="collapse">
  <li><a href="#sample-pca" id="toc-sample-pca" class="nav-link" data-scroll-target="#sample-pca"><span class="toc-section-number">11.1.1</span>  Sample PCA</a></li>
  <li><a href="#pca-with-a-large-dimension" id="toc-pca-with-a-large-dimension" class="nav-link" data-scroll-target="#pca-with-a-large-dimension"><span class="toc-section-number">11.1.2</span>  PCA with a large dimension</a></li>
  <li><a href="#simple-example" id="toc-simple-example" class="nav-link" data-scroll-target="#simple-example"><span class="toc-section-number">11.1.3</span>  Simple example</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example"><span class="toc-section-number">11.1.4</span>  Example</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="pca" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="pca"><span class="header-section-number">11.1</span> PCA</h2>
<p>Let <span class="math inline">\(\{X_i\}\)</span> for <span class="math inline">\(i=1,\ldots,n\)</span> be <span class="math inline">\(p\)</span> random vectors with means <span class="math inline">\((0,\ldots,0)^t\)</span> and variance matrix <span class="math inline">\(\Sigma\)</span>. Consider finding <span class="math inline">\(v_1\)</span>, a <span class="math inline">\(p\)</span> dimensional vector with <span class="math inline">\(||v_1|| = 1\)</span> so that <span class="math inline">\(v_1^t \Sigma v_1\)</span> is maximized. Notice this is equivalent to saying we want to maximize <span class="math inline">\(\mathrm{Var}( X_i^t V_1)\)</span>. The well known solution to this equation is that <span class="math inline">\(v_1\)</span> is the first eigenvector of <span class="math inline">\(\Sigma\)</span> and <span class="math inline">\(\lambda_1 = \mathrm{Var}( X_i^t V_1)\)</span> is the associated eigenvalue. If <span class="math inline">\(\Sigma = V^t \Lambda V\)</span> is the eigenvalue decomposition of where <span class="math inline">\(V\)</span> are the eigenvectors and <span class="math inline">\(\Lambda\)</span> is a diagonal matrix of the eigenvalues ordered from greatest to least, then <span class="math inline">\(v_1\)</span> corresponds to the first column of <span class="math inline">\(V\)</span> and <span class="math inline">\(\lambda_1\)</span> corresponds to the first element of <span class="math inline">\(\Lambda\)</span>. If one then finds <span class="math inline">\(v_k\)</span> as the vector maximizing <span class="math inline">\(v_k^t \Sigma v_k\)</span> so that <span class="math inline">\(v_k^t v_{k'} = I(k=k')\)</span>, then the <span class="math inline">\(v_k\)</span> are the columns of <span class="math inline">\(V\)</span> and <span class="math inline">\(v_k^t \Sigma v_k = \lambda_k\)</span> are the eigenvalues.</p>
<p>Notice:</p>
<ol type="1">
<li><span class="math inline">\(V \Sigma V^t = \Lambda\)</span> (i.e.&nbsp;<span class="math inline">\(V\)</span> diagonalizess <span class="math inline">\(\Sigma\)</span>)</li>
<li><span class="math inline">\(\mbox{Trace}(\Sigma) = \mbox{Trace}(\Sigma V^t V) = \mbox{Trace}(V \Sigma V^t) = \sum \lambda_k\)</span> (i.e.&nbsp;the total variability is the sum of the eigenvalues)</li>
<li>Since <span class="math inline">\(V^t V = I\)</span>, <span class="math inline">\(V\)</span> is a rotation matrix. Thus, <span class="math inline">\(V\)</span> rotates <span class="math inline">\(X_i\)</span> in such a way that to maximize variability in the first dimension, then the second dimensions …</li>
<li><span class="math inline">\(\mbox{Cov}(X_i^t v_k, x_i^t v_{k'} )= \mbox{Cov}(X_i^t v_k, x_i^t v_{k'} ) v_k^t \mbox{Cov}(x_i, x_i^t) v_{k'} = v_k^t V v_{k'} = 0\)</span> if <span class="math inline">\(k\neq k'\)</span></li>
<li>Another representation of <span class="math inline">\(\Sigma\)</span> is <span class="math inline">\(\sum_{k=1}^p \lambda_i v_k v_k^t\)</span> by simply rewriting the matrix algebra of <span class="math inline">\(V \Lambda V^t\)</span>.</li>
<li>The variables <span class="math inline">\(U_i = V X_i\)</span> then: have uncorrelated elements (<span class="math inline">\(\mbox{Cov}(U_{ik}, U_{ik'}) = 0\)</span> for <span class="math inline">\(k\neq k'\)</span> by property 5), have the same total variability as the elements of <span class="math inline">\(X_i\)</span> (<span class="math inline">\(\sum_k \mbox{Var}(U_{ik}) = \sum_k \lambda_k = \sum_k \mbox{Var}(X_{ik})\)</span> by property 2), are a rotation of the <span class="math inline">\(X_i\)</span>, are ordered so that <span class="math inline">\(U_{i1}\)</span> has the greatest amount of variability and so on.</li>
</ol>
<p>Notation:</p>
<ol type="1">
<li>The <span class="math inline">\(\lambda_k\)</span> are simply called the eigenvalues or principal components variation.</li>
<li><span class="math inline">\(U_{ik} = X_i^t v_k\)</span> is called the <strong>principal component scores</strong>.</li>
<li>The <span class="math inline">\(v_k\)</span> are called the <strong>principal component loadings</strong> or <strong>weights</strong>, with <span class="math inline">\(v_1\)</span> being called the first principal component and so on.</li>
</ol>
<p>Statistical properties</p>
<ol type="1">
<li><span class="math inline">\(E[U_{ik}]=0\)</span></li>
<li><span class="math inline">\(\mbox{Var}(U_{ik}) = \lambda_k\)</span></li>
<li><span class="math inline">\(\mbox{Cov}(U_{ik}, U_{ik'}) = 0\)</span> if <span class="math inline">\(k\neq k'\)</span></li>
<li><span class="math inline">\(\sum_{k=1}^p \mbox{Var}(U_{ik}) = \mbox{Trace}(\Sigma)\)</span>.</li>
<li><span class="math inline">\(\prod_{k=1}^p \mbox{Var}(U_{ik}) = \mbox{Det}(\Sigma)\)</span></li>
</ol>
<section id="sample-pca" class="level3" data-number="11.1.1">
<h3 data-number="11.1.1" class="anchored" data-anchor-id="sample-pca"><span class="header-section-number">11.1.1</span> Sample PCA</h3>
<p>Of course, we’re describing PCA as a conceptual process. We realize <span class="math inline">\(n\)</span> <span class="math inline">\(p\)</span> dimensional vectors <span class="math inline">\(x_1\)</span> to <span class="math inline">\(x_n\)</span>, typically organized in <span class="math inline">\(X\)</span> a <span class="math inline">\(n\times p\)</span> matrix. If <span class="math inline">\(X\)</span> is not mean 0, we typically demean it by calculating <span class="math inline">\((I- J(J^t J)^{-1} J') X\)</span> where <span class="math inline">\(J\)</span> is a vector of ones. Assume this is done. Then <span class="math inline">\(\frac{1}{n-1} X^t X = \hat \Sigma\)</span>. Thus, our sample PCA is obtained via the eigenvalue decomposition <span class="math inline">\(\hat \Sigma = \hat V \hat \Lambda \hat V^t\)</span> and our principal components obtained as $ X V$.</p>
<p>We can relate PCA to the SVD as follows. Let <span class="math inline">\(\frac{1}{\sqrt{n-1}} X = \hat U \sqrt{\hat \Lambda} \hat V^t\)</span> be the SVD of the scaled version of <span class="math inline">\(X\)</span>. Then note that <span class="math display">\[
\hat \Sigma = \frac{1}{n-1} X^t X = \hat V \hat \Lambda \hat V^t
\]</span> yields the sample covariance matrix eigenvalue decomposition.</p>
</section>
<section id="pca-with-a-large-dimension" class="level3" data-number="11.1.2">
<h3 data-number="11.1.2" class="anchored" data-anchor-id="pca-with-a-large-dimension"><span class="header-section-number">11.1.2</span> PCA with a large dimension</h3>
<p>Consider the case where one of <span class="math inline">\(n\)</span> or <span class="math inline">\(p\)</span> is large. Let’s assume <span class="math inline">\(n\)</span> is large. Then <span class="math display">\[
\frac{1}{n-1} X^t X = \frac{1}{n-1} \sum_i x_i x_i^t
\]</span> As we learned in the chapter on HDF5, we can do sums like these without loading the entirety of <span class="math inline">\(X\)</span> into memory. Thus, in this case, we can calculate the eigenvectors using only the small dimension. If, on the other hand, <span class="math inline">\(p\)</span> is large and <span class="math inline">\(n\)</span> is smaller, then we can calculate the eigenvalue decomposition of <span class="math display">\[
\frac{1}{n-1} X X^t = \hat U \hat \Lambda \hat U^t.
\]</span> In either case, whether <span class="math inline">\(U\)</span> or <span class="math inline">\(V\)</span> is easier to get, we can then obtain the other via vectorized multiplication.</p>
</section>
<section id="simple-example" class="level3" data-number="11.1.3">
<h3 data-number="11.1.3" class="anchored" data-anchor-id="simple-example"><span class="header-section-number">11.1.3</span> Simple example</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> la</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, DataLoader</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Sigma <span class="op">=</span> np.matrix([[<span class="dv">1</span>, <span class="fl">.5</span>], [<span class="fl">.5</span>, <span class="dv">1</span>]])</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.multivariate_normal( mean <span class="op">=</span> mu, cov <span class="op">=</span> Sigma, size <span class="op">=</span> n)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7c35a4745d80&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-3-output-2.png" width="569" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X <span class="op">-</span> X.mean(<span class="dv">0</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.mean(<span class="dv">0</span>))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Sigma_hat <span class="op">=</span> np.matmul(np.transpose(X), X) <span class="op">/</span> (n<span class="op">-</span><span class="dv">1</span>) </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>Sigma_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 2.73669976e-17 -2.66453526e-18]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([[1.09203671, 0.56675734],
       [0.56675734, 1.06592638]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>evd <span class="op">=</span> la.eig(Sigma_hat)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>lambda_ <span class="op">=</span> evd[<span class="dv">0</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>v_hat <span class="op">=</span> evd[<span class="dv">1</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>u_hat <span class="op">=</span> np.matmul(X, np.transpose(v_hat))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(u_hat[:,<span class="dv">0</span>], u_hat[:,<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7c35a49950f0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-5-output-2.png" width="569" height="415"></p>
</div>
</div>
<p>Fit using scikitlearn’s function</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>).fit(X)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pca.explained_variance_)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lambda_ )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.64588923 0.51207386]
[1.64588923 0.51207386]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>u_hat2 <span class="op">=</span> pca.transform(X)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(u_hat2[:,<span class="dv">0</span>], u_hat2[:,<span class="dv">1</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(u_hat2[:,<span class="dv">0</span>], u_hat[:,<span class="dv">0</span>])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(u_hat2[:,<span class="dv">1</span>], u_hat[:,<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7c35a4877670&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-7-output-2.png" width="569" height="411"></p>
</div>
</div>
</section>
<section id="example" class="level3" data-number="11.1.4">
<h3 data-number="11.1.4" class="anchored" data-anchor-id="example"><span class="header-section-number">11.1.4</span> Example</h3>
<p>Let’s consider the melanoma dataset that we looked at before. First we read in the data as we have done before so we don’t show that code.</p>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-stdout">
<pre><code>Using downloaded and verified file: /home/bcaffo/.medmnist/dermamnist.npz
Using downloaded and verified file: /home/bcaffo/.medmnist/dermamnist.npz
Using downloaded and verified file: /home/bcaffo/.medmnist/dermamnist.npz</code></pre>
</div>
</div>
<p>Next, let’s get the data from the torch dataloader format back into an image array and a matrix with the image part (28, 28, 3) vectorized.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loader_to_array(dataloader):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">## Read one iteration to get data</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  test_input, test_target <span class="op">=</span> <span class="bu">iter</span>(dataloader).<span class="bu">next</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">## Total number of training images</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> np.<span class="bu">sum</span>([inputs.shape[<span class="dv">0</span>] <span class="cf">for</span> inputs, targets <span class="kw">in</span> dataloader])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">## The dimensions of the images</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  imgdim <span class="op">=</span> (test_input.shape[<span class="dv">2</span>], test_input.shape[<span class="dv">3</span>])</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  images <span class="op">=</span> np.empty( (n, imgdim[<span class="dv">0</span>], imgdim[<span class="dv">1</span>], <span class="dv">3</span>))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">## Read the data from the data loader into our numpy array</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> inputs, targets <span class="kw">in</span> dataloader:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> inputs.detach().numpy()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(inputs.shape[<span class="dv">0</span>]):</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>      img <span class="op">=</span> inputs[j,:,:,:]</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>      <span class="co">## get it out of pytorch format</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>      img <span class="op">=</span> np.transpose(img, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>      images[idx,:,:,:] <span class="op">=</span> img</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>      idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>  matrix <span class="op">=</span> images.reshape(n, <span class="dv">3</span> <span class="op">*</span> np.prod(imgdim))</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> images, matrix</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>train_images, train_matrix <span class="op">=</span> loader_to_array(train_loader)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>test_images, test_matrix <span class="op">=</span> loader_to_array(test_loader)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co">## Demean the matrices</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>train_mean <span class="op">=</span> train_matrix.mean(<span class="dv">0</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>train_matrix <span class="op">=</span> train_matrix <span class="op">-</span> train_mean</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>test_mean <span class="op">=</span> test_matrix.mean(<span class="dv">0</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>test_matrix <span class="op">=</span> test_matrix <span class="op">-</span> test_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s actually perform PCA using scikitlearn. We’ll plot the eigenvalues divided by their sums, <span class="math inline">\(\lambda_k / \sum_{k'} \lambda_{k'}\)</span>. This is called a scree plot.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>n_comp <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> n_comp).fit(train_matrix)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.plot(pca.explained_variance_ratio_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-10-output-1.png" width="579" height="411"></p>
</div>
</div>
<p>Often this is done by plotting the cummulative sum so that you can visualize how much variance is explained by including the top <span class="math inline">\(k\)</span> components. Here I fit 10 components and they explain 85% of the variation.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plt.plot(np.cumsum(pca.explained_variance_ratio_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-11-output-1.png" width="571" height="411"></p>
</div>
</div>
<p>Let’s project our testing data onto the principal component basis created by our training data and see how it does. Let <span class="math inline">\(X_{training} = U \Lambda^{1/2} V^t\)</span> is the SVD of our training data. Then, we can convert ths scores, <span class="math inline">\(U\)</span> back to <span class="math inline">\(X_{training}\)</span> with the map <span class="math inline">\(U \rightarrow U \lambda^{1/2} V\)</span>. Or, if our scores are normalized, <span class="math inline">\(U \Lambda^{1/2}\)</span> then we simply multiply by <span class="math inline">\(V^t\)</span>. If we want to represent <span class="math inline">\(X_{training}\)</span> by a lower dimensional summary, we just keep fewer columns of scores, then multiply by the same columns of <span class="math inline">\(V\)</span>. We could write this as <span class="math inline">\(U_s = X_{training} V_S \lambda^{-1/2}_S\)</span>, where <span class="math inline">\(S\)</span> refers to a subset of values of <span class="math inline">\(k\)</span>.</p>
<p>Notice that <span class="math inline">\(\hat X_{training} = U_{S} V^t_S \Lambda^{-1/2}_S = X_{training} V_S V_S^t\)</span> , <span class="math inline">\(\Lambda\)</span> and <span class="math inline">\(V\)</span>. Consider then an approximation to <span class="math inline">\(X_{test}\)</span> as <span class="math inline">\(\hat X_{test} = X_{test} V_s V_S^t\)</span>. Written otherwise <span class="math display">\[
\hat X_{i,test} = \sum_{k \in S} &lt;x_{i,test}, v_k&gt; v_k
\]</span> which is the projection of subject <span class="math inline">\(i\)</span>’s features into the linear space spanned by the basis defined by the principal component loadings.</p>
<p>Let’s try this on our mole data.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>test_matrix_fit <span class="op">=</span> pca.inverse_transform(pca.transform(test_matrix))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>np.mean(np.<span class="bu">abs</span>( test_matrix <span class="op">-</span> test_matrix_fit))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>0.03792390855153157</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-13-output-1.png" width="768" height="354"></p>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> FastICA</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>transformer <span class="op">=</span> FastICA(n_components<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>, whiten<span class="op">=</span><span class="st">'unit-variance'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>icafit <span class="op">=</span> transformer.fit_transform(train_matrix)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>train_matrix_fit_ica <span class="op">=</span> transformer.inverse_transform(icafit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>train_matrix_remeaned <span class="op">=</span> train_matrix <span class="op">+</span> train_mean</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  plt.xticks([])</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  plt.yticks([])</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> train_matrix_remeaned[i,:].reshape(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">3</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>())</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img <span class="op">/</span> img.<span class="bu">max</span>()</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img <span class="op">*</span> <span class="dv">255</span> </span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img.astype(np.uint8)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>,i<span class="op">+</span><span class="dv">6</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  plt.xticks([])</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  plt.yticks([])</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> train_matrix_fit_ica[i,:].reshape(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">3</span>)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>())</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img <span class="op">/</span> img.<span class="bu">max</span>()</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img <span class="op">*</span> <span class="dv">255</span> </span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img.astype(np.uint8)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unsupervised_files/figure-html/cell-15-output-1.png" width="768" height="354"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./convnet_example.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Example convnet</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./data_analysis_theory.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Data science, conceptually</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>