[
  {
    "objectID": "images.html",
    "href": "images.html",
    "title": "4  Working with images",
    "section": "",
    "text": "Images broadly come in two types, vector and raster. Vector graphics are in formats like pdf, eps, svg and raster graphics are like jpeg, gif, png. Vector graphics store the image constructs and shapes. So, a vector graphics renderer can zoom in indefinitely on a shape and its edges will appear sharp. Vector fonts work this way. Raster graphics basically store a matrix and the pixels on the screen show the values of that matrix. Bitmapped fonts work this way. Of course, vector graphics have to be converted to raster to be actually displayed by the computer. Finally, some rater graphics formats have compression, which we won’t really discuss."
  },
  {
    "objectID": "images.html#working-with-raster-graphics",
    "href": "images.html#working-with-raster-graphics",
    "title": "4  Working with images",
    "section": "4.2 Working with raster graphics",
    "text": "4.2 Working with raster graphics\nRaster images are typically stored as an array. Grayscale images are matrices with the image intensity as the value and color pictures are stored as 3D arrays with the two main dimensions and color channels. A library for working with regular images in python is called PIL.\nThere are different raster specifications. RGB has 3 color channels, red, green and blue. CMYK has four: cyan, magenta, yellow and black. It’s interesting to note that the use of color channels existed before color cameras, when photographers would use different filters and additive and subtractive processes. The photograph below was created in 1877 by Louis Ducos du Hauron.\n\n\n\nColor image\n\n\nReading and working with images in python is quite easy because of the Python Image Library (PIL).\n\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimg = Image.open(\"assets/images/Duhauron1877.jpg\")\n## You can see it with this, or img.show()\nimg\n\n\n\n\nPIL objects come with a ton of methods. For example, if we want to know whether we have an RGB or CMYK image, just print its mode.\n\nprint(img.mode)\n\nRGB\n\n\n\nr, g, b = img.split()\n\nplt.figure(figsize=(10,4));\nplt.subplot(1, 3, 1);\nplt.axis('off');\nplt.imshow(r);\n\nplt.subplot(1, 3, 2);\nplt.axis('off');\nplt.imshow(g);\n\nplt.subplot(1, 3, 3);\nplt.axis('off');\nplt.imshow(b);\n\n\n\n\nIf you’re tired of working with the image as a PIL object, it’s easy to convert to a np array.\n\nimg_array = np.array(img)\nimg_array.shape\n\n(1132, 1548, 3)\n\n\nBefore we leave PIL, it should be said that most image operations can be done in it. For example, cropping.\n\nbbox = [500, 630, 700, 760]\ncropped = img.crop(bbox)\ncropped\n\n\n\n\nWe can rotate the house and put it back\n\nrot = cropped.transpose(Image.Transpose.ROTATE_180)\nrot\n\n\n\n\n\n##Note this overwrites the image\nimg.paste(rot, bbox)\nimg"
  },
  {
    "objectID": "images.html#image-mathematics",
    "href": "images.html#image-mathematics",
    "title": "4  Working with images",
    "section": "4.3 Image mathematics",
    "text": "4.3 Image mathematics\n\n4.3.1 Convolutions\n\n4.3.1.1 1D transforms\nConvolutions are an important topic in mathematics, statistics, signal processing … Let’s discuss 1D convolutions first. A real valued convolution of two continuous signals, \\(X(t)\\) and \\(K(t)\\) is defined as \\(X* K\\)\n\\[\n(X* K)(t) = \\int_{-\\infty}^{\\infty} X(u) K(t-u) du\n= \\int_{-\\infty}^{\\infty} X(t-v) K(v) dv,\n\\]\nwhere the equality is determined by a simple change of variable argument. The discrete analog is\n\\[\n(X* K)(t) = \\sum_{u = -\\infty}^{\\infty} X(u) K(t-u)\n= \\sum_{v = -\\infty}^{\\infty} X(t-v) K(v)\n\\]\nThe convolution has many, many uses in data science and statistics. For example, the convolution of densities or mass functions is the respective density or mass function for the sum of random variables from those distributions. In applied data analysis, you can think of the convolution between \\(X\\) and \\(K\\) as smearing the function \\(K\\) over the function \\(X\\). Thus, it plays a key role in smoothing. Let’s try an example using the covid data and a box kernel. We take \\(K(t) = I\\{0 \\leq t < M\\} / M\\) (i.e. is 1 for times 0 to \\(M-1\\), then rescaled so it sums to 1). Assume that \\(N\\geq M\\) and that \\(X(t)\\) and \\(K(t)\\) are \\(0\\) and for \\(t < 0\\) or \\(t > N\\). Then, our convolution works out to be\n\\[\n(X* K)(t)\n= \\sum_{u = -\\infty}^{\\infty} X(u) K(t-u)\n= \\sum_{u = 0}^{N} X(u) K(t-u)\n= \\sum_{u = t}^{t + M - 1} X(u) K(t -u)\n= \\sum_{u = t}^{t + M - 1} X(u) / M\n\\]\nThat is, our convolution is a moving average of \\(X\\) where the convolution at point \\(t\\) is the average of the points between \\(t\\) and \\(t + M - 1\\). So, the convolution, as we’ve defined it, at point \\(t\\) is the moving average at point \\(t + (M-1)/2\\) (ie. it’s shifted by \\((M-1)/2\\)). Also, at the end (\\(t \\geq N - M + 1\\)), we’re averaging in the assumed zero values of the \\(X\\). This might be reasonable to do, or maybe not. The fact that we’re padding the end and not the beginning is just because of the range of index values we defined the kernel on. We’d have the same problem only on the other end if \\(K(t) = I(-M < t \\leq 0)/M\\). Of course, the computer will start summing things at index 0 regardless. However, it can shift the kernel relative to the signal arbitrarily by zero padding one end or the other or both. A reasonable strategy is to set it so that it averages in \\((M-1)/2\\) on both ends. Numpy allows you to only look at the range of \\(N - M\\) middle values where this isn’t an issue (argument mode = \"valid\").\nNote we could make the kernel weight points differently than just a box kernel. A popular choice is a Gaussian distribution.\nAlso, the convolution has \\(N+M-1\\) points. So, it has more time points than the original signal. Numpy has options to shift the convolution back into the same space as the original signal for you (i.e. has \\(N\\) points, mode = \"same\"). Or, you can just do it yourself if you do mode = \"full\", just shift by \\((M-1)/2\\). Similarly shift for mode = \"valid\" (but the convolution has fewer points in this case, so it won’t have corresponding points with \\(X\\) at the very beginning and end).\nHere’s an example using Italy’s daily covid case count data. We plot the data and the convolution smoothed data. In the bottom panels, we show the residuals to highlight the difference.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\ndat = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n## Get Italy, drop everyrthing except dates, convert to long (unstack converts to tuple)\nX = dat[dat['Country/Region'] == 'Italy'].drop([\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], axis=1).unstack()\n## convert from tuple to array\nX = np.asarray(X)  \n## get case counts instead of cumulative counts\nX = X[1 : X.size] - X[0 : (X.size - 1)]\n## get the first non zero entry\nX =  X[np.min(np.where(X !=  0)) : X.size]\nplt.plot(X)\n\n\n\n\nNow let’s plot the convolutions with different options in np.convolve.\n\n## 41 day moving average\nN = len(X)\nM = 41\n\nfig, axes = plt.subplots(2, 3, figsize = [12.4, 12.4])\naxes[0,0].plot(X)\naxes[0,1].plot(X)\naxes[0,2].plot(X)\n\nK = np.ones(M) / M\n\n## Plot the convolution with the argument 'same'\n## this gives N (assumed greater than M) points\nXC = np.convolve(X, K, 'same')\naxes[0,0].plot(XC)\naxes[1,0].plot(X - XC)\n\n## Plot the convolution with the argument 'full'\n## which gives N+M-1 total pionts\nXC = np.convolve(X, K, 'full')\ntemp = np.pad(X, (M-1, 0), 'constant') \naxes[0,1].plot(XC)\naxes[1,1].plot(temp- XC)\n\n\n## Plot the convolution with the convolution shifted back by (M-1)/2\nXCshifted = XC[ (int((M - 1)/2)) : int(len(XC) - (M - 1)/2) ]\naxes[0, 2].plot(XCshifted)\naxes[1, 2].plot(X - XCshifted)\n## 41 day moving average\nN = len(X)\nM = 41\n\nfig, axes = plt.subplots(2, 3, figsize = [12.4, 12.4])\naxes[0,0].plot(X)\naxes[0,1].plot(X)\naxes[0,2].plot(X)\n\nK = np.ones(M) / M\n\n## Plot the convolution with the argument 'same'\n## this gives N (assumed greater than M) points\nXC = np.convolve(X, K, 'same')\naxes[0,0].plot(XC)\naxes[1,0].plot(X - XC)\n\n## Plot the convolution with the argument 'full'\n## which gives N+M-1 total pionts\nXC = np.convolve(X, K, 'full')\ntemp = np.pad(X, (M-1, 0), 'constant') \naxes[0,1].plot(XC)\naxes[1,1].plot(temp- XC)\n\n\n## Plot the convolution with the convolution shifted back by (M-1)/2\nXCshifted = XC[ (int((M - 1)/2)) : int(len(XC) - (M - 1)/2) ]\naxes[0, 2].plot(XCshifted)\naxes[1, 2].plot(X - XCshifted)\n\n\n\n\n\n\n\nLet’s show that the first point and end point of the convolution are the averages of \\((M-1)/2\\) points and and \\((M-1)/2+1\\) zeros at the beginning or end of the original signal just to show that our intuition is correct.\n\ntemp = np.convolve(X, K, 'same')\n[\n  # the first convolution point (temp[0]) and the average of the\n  # the first (M-1) / 2 X points and (M-1)/2 + 1 zeros\n  [temp[0],     X[0 : int(    (M - 1) / 2)].sum() / M],\n  # the last convolution point (temp[N-1]) and the average of the\n  # the last (M-1) / 2 X points and (M-1)/2 + 1 zeros\n  [temp[N - 1], X[int(N - (M - 1) / 2 - 1)  : N].sum() / M]\n \n]\n\n[[0.07317073170731708, 0.07317073170731707],\n [10552.90243902439, 10552.90243902439]]\n\n\nAlso, I averaged a lot (41 days) in order to make the shift very apparent. Let’s look at the performance for less wide of a kernel.\n\n## 21 day moving average\nM = 21\nK = np.ones(M) / M\n\nfig, axes = plt.subplots(1, 2, figsize = [12.4, 6.2])\nXC = np.convolve(X, K, 'same')\naxes[0].plot(X)\naxes[0].plot(XC)\naxes[1].plot(X - XC)\n\n\n\n\nIt should be stated that the convolution operation is multiplication in Fourier space. So, functions like np.convolve are performing FFTs in the background. However, if you’re going to do this yourself, make sure to keep track of indices and zero padding. (I.e. the bookkeeping.) Otherwise, the FFT wraps around and you get a little of the end averaged in with the beginning and vice versa. I work out getting the same answer as mode = “same” below.\n\nfig, axes = plt.subplots(1, 2, figsize = [12.4, 6.2])\n\n## Pad the X with zeros in the back, need at least M-1 \npad_width = (0, M - 1)\nXpadded = np.pad(X, pad_width, \"constant\")\n## Pad the kernel in the back with N-1, so both the kernel\n## and the X are of length, N+M-1\nKpadded = np.pad(K, (0, N - 1))\n\n## Note we take the real part b/c the complex part is all effectively \n## machine 0\nconvolution = np.fft.ifft(np.fft.fft(Xpadded) * np.fft.fft(Kpadded)).real\n\n## At this point the convolution is of length N + M - 1\n## To get it comparable with the original X, subtract (M-1)/2 indices\n## from each end\nconvolution = convolution[ int((M-1)/2) : int(N+(M-1)/2)]\n\n## Let's see how we did\naxes[0].plot(X)\naxes[0].plot(convolution)\n\n#Show they're the same by plotting the subtraction\naxes[1].plot(convolution - XC)\n\n\n\n\n\n\n4.3.1.2 2D transforms\nFor two dimensions, the convolution is similar\n\\[\n(X ** K)(i,j) = \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty}\nX(u, v)  K(i -u, k - v) = \\sum_{u=-\\infty}^{\\infty} \\sum_{v=-\\infty}^{\\infty}\nK(u, v)  X(i -u, k - v)  \n\\]\nOnce again, let’s think where \\(X\\) is of dimension \\((N_1, N_2)\\) and 0 outside of that range, and\n\\[\nK(u, v) = I(0 \\leq u < M_1, 0 \\leq v < M_2) / (M_1 M_2)\n\\]\n(i.e. \\(K\\) is a box on \\(M_1 \\leq N_1\\), \\(M_2 < N_2\\)). Then, applying the exact same argument as before, the convolution is:\n\\[\n(X ** K)(i,j) = \\sum_{u=i}^{M_1 + i - 1} \\sum_{v=j}^{M_2 + j - 1}\nX(u, v) / (M_1 M_2)\n\\]\nThat is, the convolution at point \\((i,j)\\) is the average of the neighboring points. Also, all of the same bookkeeping, zero padding and Fourier transform stuff apply (using the 2D FFT).\nFor regular kernels (box kernels, 2D Gaussians), convolution smooths the image, which has the efffect of making it blurrier. The kernel width determines how blurry the image will then be. This is typically done to denoise an image (to blur out the noise). Let’s try it on a cartoon image of Brian. We’ll just stick to a black and white image so that it’s 2D. A color image has 3 color channels, so is a 3D array. (However, you see the patten; you should be able to extend this to 3D with little problem.)\n\nimport PIL\nimport scipy.signal as sp\nimport urllib.request\n\n\nimgURL = \"https://github.com/smart-stats/ds4bio_book/raw/main/book/bcCartoon.png\"\nurllib.request.urlretrieve(imgURL, \"bcCartoon.png\")\nimg = np.asarray(PIL.Image.open(\"bcCartoon.png\").convert(\"L\"))\n\nplt.xticks([])\nplt.yticks([])\nplt.imshow(img, cmap='gray', vmin=0, vmax=255)\n\n<matplotlib.image.AxesImage at 0x7bbda5398eb0>\n\n\n\n\n\nNow let’s take this image and convolve it with different kernels of different window lengths.\n\ndef kernel(i, j):\n  return np.ones((i, j)) / np.prod([i, j])\n\nplt.figure(figsize=[12.4, 12.4])\nimgC = sp.convolve2d(img, kernel(4, 4))\nplt.subplot(2, 2, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(imgC, cmap='gray', vmin=0, vmax=255)\nplt.title(\"4x4\")\n\nimgC = sp.convolve2d(img, kernel(8, 8))\nplt.subplot(2, 2, 2)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(imgC, cmap='gray', vmin=0, vmax=255)\nplt.title(\"8x8\")\n\nimgC = sp.convolve2d(img, kernel(16, 16))\nplt.subplot(2, 2, 3)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(imgC, cmap='gray', vmin=0, vmax=255)\nplt.title(\"16x16\")\n\nboxsize = (5, 5)\nimgC = sp.convolve2d(img, kernel(32,32))\nplt.subplot(2, 2, 4)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(imgC, cmap='gray', vmin=0, vmax=255)\nplt.title(\"32x32\")\n\nText(0.5, 1.0, '32x32')\n\n\n\n\n\n\n\n4.3.1.3 Convolutional neural networks\nOf course, your kernel doesn’t have to be a box, or a truncated, discretized bivariate Gaussian density or even be non-negative. It’s helpful for smoothers to have non-negative kernels, since they’re just taking a generalized variation of a moving average that way. But, we want to use convolutions\nmore generally. Here, let’s take a kernel that is part of the image (left eye) and convolve it. I’ll make the kernel super peaked at eye features by extracting the eye and raising it to the 4th power.\nSo a relu activation function plus a bias term would then be able to highlight different thresheld variations of this convolution image. For example, here I add a bias term to the convolution then apply a leaky relu. You can see it just highlights the one area where the eye is. A leaky relu is\n\\[\nlrelu(x, c) = \\left\\{\n  \\begin{array}{ll}\n  x & \\text{if $x > 0$} \\\\\n  x * c & \\text{otherwise}\n  \\end{array}\n  \\right.\n\\]\nwhere \\(c\\) is usually set to a small value. If \\(c=0\\) the leaky relu is just the relu. I set \\(c\\) to be 0.05 so that we can see the background image.\n\nplt.figure(figsize=[12.4, 6.2])\n\nK = img[200 : 270,225 : 322]\nplt.subplot(1, 3, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(K,  cmap='gray', vmin=0, vmax=255)\n## I normalized it this way so that the convolution\n## numbers wouldn't be so big\n## Also, I put it to the 4th power, so it exactly finds \n## the eye.\nK = K ** 4\nK = K / K.sum()\nK = K - K.mean()\n\nimgC = sp.convolve2d(img, K)\nplt.subplot(1, 3, 2)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(imgC)\nplt.title(\"Convolution\")\n\ntemp = imgC.copy()\n## Add a bias term of -15\ntemp -= 15\n## Perform a leaky relu\ntemp[np.where(temp < 0)] = temp[np.where(temp < 0)] * .05\n\nplt.subplot(1, 3, 3)\nplt.imshow(temp)\nplt.xticks([])\nplt.yticks([])\nplt.title(\"LRELU of convolution + bias\")\n\nText(0.5, 1.0, 'LRELU of convolution + bias')\n\n\n\n\n\nBecause of how convolutions work, this will find this eye anywhere in the image. Here we just add another eye somewhere else and repeat the convolution.\n\nplt.figure(figsize=[12.4, 6.2])\n\n#put another eye in the image\nimgCopy = img.copy()\nimgCopy[60 : 130, 85 : 182] = img[200 : 270,225 : 322]\nplt.subplot(1, 2, 1)\nplt.imshow(imgCopy,  cmap='gray', vmin=0, vmax=255)\nplt.xticks([])\nplt.yticks([])\n\nimgC = sp.convolve2d(imgCopy, K)\n\nplt.subplot(1, 2, 2)\ntemp = imgC.copy()\n## Add a bias term of -15\ntemp -= 15\n## Perform a leaky relu\ntemp[np.where(temp < 0)] = temp[np.where(temp < 0)] * .05\n\nplt.subplot(1, 2, 2)\nplt.imshow(temp)\nplt.xticks([])\nplt.yticks([])\nplt.title(\"LRELU of convolution + bias\")\n\nText(0.5, 1.0, 'LRELU of convolution + bias')\n\n\n\n\n\nSo, we found a custom kernel that highlights this specific feature in images. Convnets layers learn the kernel. That is, CNNs learn the image that gets convolved with the previous layer to produce the next one. Here’s a really great pictorial guide by Sumit Saha.\nNow, let’s discuss some specific vocabulary used in CNNs.\n\nPadding zero padding just like we discussed for 1D transformations\nPooling pooling, often max pooling, is a dimension reduction technique, taking the max in little blocks.\nstride length instead of sliding the kernel by moving it one pixel at a time, move it more to increase computational efficiency and reduce the size of the output convolution."
  },
  {
    "objectID": "images.html#medical-images",
    "href": "images.html#medical-images",
    "title": "4  Working with images",
    "section": "4.4 Medical images",
    "text": "4.4 Medical images\nMedical images offer unique challenges for imaging. A common format for medical images is dicom. Most medical images are 3D or 4D grayscale images.\nTo get a sense of working with medical images, let’s consider a set of 2D images.\n\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\ndata_flag = 'dermamnist'\ninfo = INFO[data_flag]\ntask = info['task']\nn_channels = info['n_channels']\nn_classes = len(info['label'])\nDataClass = getattr(medmnist, info['python_class'])\ntrain_dataset = DataClass(split='train', download = True)\n\nUsing downloaded and verified file: /home/bcaffo/.medmnist/dermamnist.npz\n\n\n\ntrain_dataset.montage(length=20)\n\n/home/bcaffo/miniconda3/envs/ds4bio/lib/python3.10/site-packages/medmnist/utils.py:25: FutureWarning:\n\n`multichannel` is a deprecated argument name for `montage`. It will be removed in version 1.0. Please use `channel_axis` instead."
  }
]